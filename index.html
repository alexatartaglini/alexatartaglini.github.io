<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <!-- Open Graph (Facebook, LinkedIn, Slack, etc.) -->
  <meta property="og:title" content="Alexa Tartaglini | about">
  <meta property="og:description" content="Stanford CS PhD student. Researching interpretability and multimodality.">
  <meta property="og:image" content="https://www.alexatartaglini.com/assets/images/preview.png">
  <meta property="og:url" content="https://www.alexatartaglini.com/">
  <meta property="og:type" content="website">

  <!-- Twitter Card (Twitter / X) -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Alexa Tartaglini | about">
  <meta name="twitter:description" content="Stanford CS PhD student. Researching interpretability and multimodality.">
  <meta name="twitter:image" content="https://www.alexatartaglini.com/assets/images/preview.png">

  <title>Alexa Tartaglini | about</title>
  <link rel="icon" type="image/svg+xml" href="assets/images/favicon.svg" />
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="assets/css/main.css" />
</head>
<body class="about-page">
  <header>
    <nav class="navbar" aria-label="Primary navigation">
      <a class="brand" href="index.html">
        <h1>Alexa R. Tartaglini</h1>
        <span>Computer Science PhD · Stanford University</span>
      </a>
      <div class="nav-links" role="list">
        <a class="nav-link active" href="index.html">about</a>
        <a class="nav-link" href="cv.html">cv</a>
        <a class="nav-link" href="misc.html">misc</a>
      </div>
      <div class="social-links" aria-label="Social links">
        <a href="https://scholar.google.com/citations?user=uD_p5lkAAAAJ&hl=en&oi=ao" aria-label="Google Scholar" title="Google Scholar" target="_blank" rel="noopener noreferrer">
          <svg id='Google_Scholar_24' width='24' height='24' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'><rect width='24' height='24' stroke='none' fill='#000000' opacity='0'/>
            <g transform="matrix(1.16 0 0 1.16 12 12)" >
            <path style="stroke: none; stroke-width: 1; stroke-dasharray: none; stroke-linecap: butt; stroke-dashoffset: 0; stroke-linejoin: miter; stroke-miterlimit: 4; fill: currentColor; fill-rule: nonzero; opacity: 1;" transform=" translate(-11.5, -12.64)" d="M 11 4 L 3 9 L 8.4921875 9 C 8.4715892 9.0754986 8.4383718 9.1441171 8.421875 9.2226562 C 8.375875 9.4646562 8.3398437 9.7308125 8.3398438 10.007812 C 8.3398438 13.578812 11.990234 13.175781 11.990234 13.175781 L 11.990234 14.085938 C 11.990234 14.454937 12.47425 14.327172 12.53125 15.076172 C 12.28925 15.076172 7.4746094 14.937547 7.4746094 18.185547 C 7.4746094 21.445547 11.724609 21.285156 11.724609 21.285156 C 11.724609 21.285156 16.632812 21.504656 16.632812 17.472656 C 16.634813 15.063656 13.822266 14.2795 13.822266 13.3125 C 13.822266 12.3335 15.941406 12.045906 15.941406 9.7539062 C 15.941406 8.7519062 15.872828 8.03825 15.423828 7.53125 C 15.388828 7.49625 15.366031 7.4722188 15.332031 7.4492188 C 15.324304 7.4420199 15.31448 7.4367774 15.306641 7.4296875 L 15.429688 7.4296875 L 17.5 5.8769531 L 17.5 8 C 17.49942941827197 8.03873573418044 17.503362127837885 8.077406561657423 17.511719 8.1152344 C 17.191943182629654 8.294143800780217 16.995610574762715 8.633604203069284 17 9 L 17 10 C 16.994899710454515 10.36063591657757 17.184375296169332 10.696081364571606 17.49587284971433 10.877887721486518 C 17.80737040325933 11.059694078401428 18.19262959674067 11.059694078401428 18.50412715028567 10.877887721486516 C 18.815624703830668 10.696081364571606 19.005100289545485 10.360635916577568 19 10 L 19 9 C 19.004389425237285 8.633604203069284 18.808056817370346 8.294143800780217 18.488281 8.1152344 C 18.496637872162115 8.077406561657423 18.50057058172803 8.03873573418044 18.5 8 L 18.5 5.125 L 20 4 L 11 4 z M 11.691406 7.0527344 C 11.979219 7.0397031 12.268922 7.109625 12.544922 7.265625 C 12.751922 7.369625 12.946141 7.518125 13.119141 7.703125 C 13.476141 8.060125 13.7765 8.5784531 13.9375 9.1894531 C 14.3175 10.640453 13.823828 12.035781 12.798828 12.300781 C 11.784828 12.587781 10.654672 11.641172 10.263672 10.201172 C 10.090672 9.4991719 10.114547 8.8202969 10.310547 8.2792969 C 10.312395 8.2723193 10.316443 8.2666961 10.318359 8.2597656 C 10.321722 8.2581149 10.32682 8.253536 10.330078 8.2519531 C 10.386262 8.0380596 10.478099 7.8461668 10.589844 7.6875 C 10.795388 7.3872165 11.066477 7.1838352 11.404297 7.09375 C 11.499297 7.07075 11.595469 7.0570781 11.691406 7.0527344 z M 12.082031 15.685547 C 13.775031 15.558547 15.216313 16.490813 15.320312 17.757812 C 15.390313 19.013813 14.087812 20.131094 12.382812 20.246094 C 10.689813 20.361094 9.2274844 19.441547 9.1464844 18.185547 C 9.0654844 16.918547 10.377031 15.812547 12.082031 15.685547 z" stroke-linecap="round" />
            </g>
          </svg>
        </a>
        <a href="https://github.com/alexatartaglini" aria-label="GitHub" title="GitHub" target="_blank" rel="noopener noreferrer">
          <svg id='GitHub_24' width='24' height='24' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'><rect width='24' height='24' stroke='none' fill='#000000' opacity='0'/>
            <g transform="matrix(0.83 0 0 0.83 12 12)" >
            <path style="stroke: none; stroke-width: 1; stroke-dasharray: none; stroke-linecap: butt; stroke-dashoffset: 0; stroke-linejoin: miter; stroke-miterlimit: 4; fill: currentColor; fill-rule: nonzero; opacity: 1;" transform=" translate(-15, -14.82)" d="M 15 3 C 8.373 3 3 8.373 3 15 C 3 20.623 6.872 25.328 12.092 26.630000000000003 C 12.036 26.468 12 26.28 12 26.047 L 12 23.996000000000002 C 11.513 23.996000000000002 10.697 23.996000000000002 10.492 23.996000000000002 C 9.671000000000001 23.996000000000002 8.941 23.643 8.587000000000002 22.987000000000002 C 8.194 22.258000000000003 8.126000000000001 21.143 7.152000000000001 20.461000000000002 C 6.863000000000001 20.234 7.083000000000001 19.975 7.416000000000001 20.01 C 8.031 20.184 8.541 20.606 9.021 21.232000000000003 C 9.499 21.859 9.724 22.001 10.617 22.001 C 11.05 22.001 11.698 21.976000000000003 12.308000000000002 21.880000000000003 C 12.636000000000001 21.047000000000004 13.203000000000001 20.28 13.896 19.918000000000003 C 9.9 19.507 7.993000000000001 17.519000000000002 7.993000000000001 14.820000000000004 C 7.993000000000001 13.658000000000005 8.488000000000001 12.534000000000004 9.329 11.587000000000003 C 9.053 10.647 8.706 8.73 9.435 8 C 11.233 8 12.32 9.166 12.581 9.481 C 13.477 9.174 14.461 9 15.495 9 C 16.531 9 17.519 9.174 18.416999999999998 9.483 C 18.675 9.17 19.763 8 21.565 8 C 22.297 8.731 21.946 10.656 21.667 11.594 C 22.503 12.539 22.995 13.66 22.995 14.82 C 22.995 17.517 21.091 19.504 17.101 19.917 C 18.199 20.49 19 22.1 19 23.313 L 19 26.046999999999997 C 19 26.150999999999996 18.977 26.225999999999996 18.965 26.314999999999998 C 23.641 24.676 27 20.236 27 15 C 27 8.373 21.627 3 15 3 z" stroke-linecap="round" />
            </g>
          </svg>
        </a>
        <a href="https://x.com/ARTartaglini" aria-label="Twitter" title="Twitter" target="_blank" rel="noopener noreferrer">
          <svg id='TwitterX_24' width='24' height='24' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'><rect width='24' height='24' stroke='none' fill='#000000' opacity='0'/>
            <g transform="matrix(1.03 0 0 1.03 12 12)" >
            <path style="stroke: none; stroke-width: 1; stroke-dasharray: none; stroke-linecap: butt; stroke-dashoffset: 0; stroke-linejoin: miter; stroke-miterlimit: 4; fill: currentColor; fill-rule: nonzero; opacity: 1;" transform=" translate(-12.12, -12)" d="M 2.3671875 3 L 9.4628906 13.140625 L 2.7402344 21 L 5.3808594 21 L 10.644531 14.830078 L 14.960938 21 L 21.871094 21 L 14.449219 10.375 L 20.740234 3 L 18.140625 3 L 13.271484 8.6875 L 9.2988281 3 L 2.3671875 3 z M 6.2070312 5 L 8.2558594 5 L 18.033203 19 L 16.001953 19 L 6.2070312 5 z" stroke-linecap="round" />
            </g>
          </svg>
        </a>
        <a href="https://www.linkedin.com/in/alexa-tartaglini/" aria-label="LinkedIn" title="LinkedIn" target="_blank" rel="noopener noreferrer">
          <svg id='LinkedIn_24' width='24' height='24' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'><rect width='24' height='24' stroke='none' fill='#000000' opacity='0'/>
            <g transform="matrix(0.91 0 0 0.91 12 12)" >
            <path style="stroke: none; stroke-width: 1; stroke-dasharray: none; stroke-linecap: butt; stroke-dashoffset: 0; stroke-linejoin: miter; stroke-miterlimit: 4; fill: currentColor; fill-rule: nonzero; opacity: 1;" transform=" translate(-15, -15)" d="M 24 4 L 6 4 C 4.895 4 4 4.895 4 6 L 4 24 C 4 25.105 4.895 26 6 26 L 24 26 C 25.105 26 26 25.105 26 24 L 26 6 C 26 4.895 25.105 4 24 4 z M 10.954 22 L 8.004000000000001 22 L 8.004000000000001 12.508 L 10.954 12.508 L 10.954 22 z M 9.449 11.151 C 8.498 11.151 7.729 10.379999999999999 7.729 9.431 C 7.729 8.482 8.499 7.711999999999999 9.449 7.711999999999999 C 10.397 7.711999999999999 11.168 8.482999999999999 11.168 9.431 C 11.168 10.38 10.397 11.151 9.449 11.151 z M 22.004 22 L 19.056 22 L 19.056 17.384 C 19.056 16.283 19.036 14.867 17.523 14.867 C 15.988 14.867 15.751999999999999 16.066000000000003 15.751999999999999 17.304000000000002 L 15.751999999999999 22 L 12.803999999999998 22 L 12.803999999999998 12.508 L 15.633999999999999 12.508 L 15.633999999999999 13.805 L 15.673999999999998 13.805 C 16.067999999999998 13.059 17.029999999999998 12.272 18.464999999999996 12.272 C 21.451999999999998 12.272 22.003999999999998 14.238 22.003999999999998 16.794 L 22.003999999999998 22 z" stroke-linecap="round" />
            </g>
          </svg>
        </a>
      </div>
    </nav>
  </header>

  <main>
    <section class="hero" aria-labelledby="hero-heading">
      <div id="hero-p5" role="presentation" aria-hidden="true"></div>
      <div class="hero-content">
        <h2 id="hero-heading">Towards a cognitive science for neural networks</h2>
        <p>
          I’m a second year Computer Science PhD student @ Stanford, advised by <a href="https://stanford.edu/~cgpotts/" target="_blank" rel="noopener noreferrer">Christopher Potts</a> 
          and <a href="https://cogtoolslab.github.io/about.html" target="_blank" rel="noopener noreferrer">Judith Fan</a>. 
          My primary research interests are <span class="accent-dark">deep neural network interpretability</span> and 
          <span class="accent-dark">multimodal reasoning</span>, drawing inspiration 
          from cognitive science. The questions I’m the most excited about lie at the intersection of vision, language, and thought.
          How do neural networks see the world, and why do they continue to struggle on some of the most fundamental tasks 
          studied by cognitive scientists?
        </p>
      </div>
      <div class="animation-controls" role="group" aria-label="Scroll controls">
        <button type="button" class="scroll-down" aria-label="Scroll to content" title="scroll down">
          <!-- Down arrow SVG -->
          <svg id='Arrows Button Down' width='24' height='24' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'><rect width='24' height='24' stroke='none' fill='#000000' opacity='0'/>
            <g transform="matrix(1.54 0 0 1.54 12 12)" >
            <path style="stroke: currentColor; stroke-width: 1; stroke-dasharray: none; stroke-linecap: round; stroke-dashoffset: 0; stroke-linejoin: round; stroke-miterlimit: 4; fill: none; fill-rule: nonzero; opacity: 1;" transform=" translate(-7, -7)" d="M 0.5 3.85 L 6.65 10 C 6.740733331544497 10.096677225793572 6.867414090340244 10.151518645886863 7 10.151518645886863 C 7.132585909659756 10.151518645886863 7.259266668455504 10.096677225793572 7.3500000000000005 10 L 13.5 3.85" stroke-linecap="round" />
            </g>
          </svg>
        </button>

        <button type="button" class="seed-button" aria-label="New Seed" title="new seed">
          <!-- You can use a refresh icon or emoji -->
          <svg id='Dice_24' width='24' height='24' viewBox='0 0 24 24' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'><rect width='24' height='24' stroke='none' fill='#000000' opacity='0'/>
            <g transform="matrix(0.83 0 0 0.83 12 12)" >
            <path style="stroke: none; stroke-width: 1; stroke-dasharray: none; stroke-linecap: butt; stroke-dashoffset: 0; stroke-linejoin: miter; stroke-miterlimit: 4; fill: currentColor; fill-rule: nonzero; opacity: 1;" transform=" translate(-15, -14.99)" d="M 15 2.9980469 C 14.626 2.9980469 14.253484 3.0699375 13.896484 3.2109375 L 5.4746094 6.5234375 C 4.8686094 6.7614375 4.8570312 7.6151406 5.4570312 7.8691406 L 14.410156 11.664062 C 14.599156 11.744063 14.799 11.783203 15 11.783203 C 15.201 11.783203 15.401844 11.744062 15.589844 11.664062 L 24.542969 7.8691406 C 25.142969 7.6151406 25.131391 6.7614375 24.525391 6.5234375 L 16.103516 3.2109375 C 15.746516 3.0699375 15.374 2.9980469 15 2.9980469 z M 15 6 C 16.105 6 17 6.448 17 7 C 17 7.552 16.105 8 15 8 C 13.895 8 13 7.552 13 7 C 13 6.448 13.895 6 15 6 z M 3.8847656 9.5097656 C 3.4066406 9.5609531 3 9.9631406 3 10.494141 L 3 20.541016 C 3 21.689016 3.6409219 22.719516 4.6699219 23.228516 C 4.6699219 23.228516 9.3001094 25.507609 12.037109 26.849609 C 12.945109 27.294609 14 26.631094 14 25.621094 L 14 15.052734 C 14 14.209734 13.496703 13.448141 12.720703 13.119141 L 4.3730469 9.5839844 C 4.2100469 9.5149844 4.0441406 9.4927031 3.8847656 9.5097656 z M 26.115234 9.5097656 C 25.955859 9.4927031 25.789953 9.5149844 25.626953 9.5839844 L 17.279297 13.119141 C 16.503297 13.448141 16 14.209734 16 15.052734 L 16 25.621094 C 16 26.632094 17.054891 27.295562 17.962891 26.851562 C 20.699891 25.509563 25.330078 23.230469 25.330078 23.230469 C 26.359078 22.720469 27 21.689016 27 20.541016 L 27 10.494141 C 27 9.9631406 26.593359 9.5609531 26.115234 9.5097656 z M 5.7988281 12.287109 C 5.8639063 12.287623 5.931 12.298562 6 12.320312 C 6.552 12.493313 7 13.305766 7 14.134766 C 7 14.963766 6.552 15.494312 6 15.320312 C 5.448 15.147312 5 14.334859 5 13.505859 C 5 12.780484 5.3432813 12.283514 5.7988281 12.287109 z M 24.201172 12.646484 C 24.656719 12.643066 25 13.140734 25 13.865234 C 25 14.693234 24.552 15.506687 24 15.679688 C 23.448 15.852688 23 15.322141 23 14.494141 C 23 13.666141 23.448 12.853687 24 12.679688 C 24.069 12.657937 24.136094 12.646973 24.201172 12.646484 z M 20.201172 14.287109 C 20.656719 14.283691 21 14.781359 21 15.505859 C 21 16.333859 20.552 17.147312 20 17.320312 C 19.448 17.493312 19 16.962766 19 16.134766 C 19 15.306766 19.448 14.494312 20 14.320312 C 20.069 14.298562 20.136094 14.287598 20.201172 14.287109 z M 24.201172 18.287109 C 24.656719 18.283691 25 18.781359 25 19.505859 C 25 20.333859 24.552 21.147312 24 21.320312 C 23.448 21.493312 23 20.962766 23 20.134766 C 23 19.306766 23.448 18.494312 24 18.320312 C 24.069 18.298562 24.136094 18.287598 24.201172 18.287109 z M 9.7988281 20.287109 C 9.8639062 20.287623 9.931 20.298562 10 20.320312 C 10.552 20.493312 11 21.305766 11 22.134766 C 11 22.963766 10.552 23.494312 10 23.320312 C 9.448 23.147313 9 22.334859 9 21.505859 C 9 20.780484 9.3432813 20.283514 9.7988281 20.287109 z M 20.201172 20.287109 C 20.656719 20.283691 21 20.781359 21 21.505859 C 21 22.333859 20.552 23.147312 20 23.320312 C 19.448 23.493312 19 22.962766 19 22.134766 C 19 21.306766 19.448 20.494313 20 20.320312 C 20.069 20.298562 20.136094 20.287598 20.201172 20.287109 z" stroke-linecap="round" />
            </g>
          </svg>
        </button>
      </div>
    </section>

    <div class="layout">
      <aside class="bio-card" aria-labelledby="bio-heading">
        <h3 id="bio-heading">// bio //</h3>
        <img src="assets/images/headshot2.jpg" alt="Alexa Tartaglini" />
        <div class="bio-scroll" tabindex="0">
          <p>
            Prior to starting my PhD, I was an undergraduate at NYU’s Courant Institute of Mathematical Sciences, where I completed a double B.A. in mathematics and computer science (2018-2023). I joined the Human & Machine Learning lab in 2019 as an Undergraduate Researcher under the supervision of 
            <a href="https://www.cs.princeton.edu/~bl8144/" target="_blank" rel="noopener noreferrer">Brenden Lake</a> and 
            <a href="https://www.waikeenvong.com/" target="_blank" rel="noopener noreferrer">Wai Keen Vong</a>.
          </p>
          
          <p>
            During this time, I worked on a number of projects that aimed to make progress on the following questions: (1) what do deep neural networks actually learn from training on ImageNet? (2) what are the limitations of using pre-trained ImageNet models as off-the-shelf “eyes” for downstream tasks? (3) how can we design benchmarks that enable truly informative and “species-fair” comparisons between human and machine intelligence? My honors thesis, “Human-Machine Perceptual Divergence: Two Investigations on How Neural Networks See the World,” was the recipient of the 
            <a href="https://nyudatascience.medium.com/the-minds-brains-machines-initiative-driving-innovation-at-the-intersection-of-natural-and-687fc60c99af" target="_blank" rel="noopener noreferrer">NYU Minds, Brains, and Machines Initiative’s Robert J. Glushko Prize</a>.
          </p>
          
          <p>
            In addition to this work, I was selected as a trainee for the NIH-affiliated Training Program in Computational Neuroscience at NYU’s 
            <a href="https://as.nyu.edu/departments/cns.html" target="_blank" rel="noopener noreferrer">Center for Neural Science</a> under the mentorship of 
            <a href="https://as.nyu.edu/faculty/weiji-ma.html" target="_blank" rel="noopener noreferrer">Wei Ji Ma</a> (2020-2021). I learned a lot about the methods used to understand human visual intelligence as well as the various strengths and failure modes of the primate visual system, which now serves as a source of inspiration for some of my current ideas.
          </p>
          
          <p>
            In particular, I’m interested in applying neuroscience frameworks and methodologies to the study of machine intelligence, as well as studying tasks that are easy for biological systems but difficult for machines.
          </p>
          
          <p>
            In my position as a Research Scientist at NYU CDS (2023-2024), I worked on using mechanistic interpretability to find symbols (abstract visual relations) in Vision Transformers in collaboration with
            <a href="https://cs.brown.edu/people/epavlick/" target="_blank" rel="noopener noreferrer">Ellie Pavlick</a> and Brown University’s 
            <a href="https://lunar.cs.brown.edu/" target="_blank" rel="noopener noreferrer">Language Understanding and Representation Lab</a>.
          </p>
        </div>
      </aside>
      
      <!-- New bottom-left animation card -->
      <section class="animation-card" aria-labelledby="viz-heading">
        <div id="side-canvas" role="presentation" aria-hidden="true"></div>
      </section>

      <div class="content-column">
        <section class="section-card" aria-labelledby="research-heading">
          <h2 id="research-heading">>>  research directions  <<</h2>
          <p>
            I study how neural networks represent and reason about the world, 
            drawing on ideas from cognitive science. Current threads include:
          </p>
          <ul>
            <li><strong>Symbols in neural networks.</strong> 
              How do abstract concepts // symbolic structures emerge in DNNs? 
              What mechanisms allow systems to move from continuous sensory input &rarr; discrete representations?
              Does a lack of symbolic structure explain persistent limitations of these models?
            </li>
            <li>
              <strong>Thinking across modalities.</strong>
              How do different modalities (e.g. vision, language) afford distinct kinds of reasoning? 
              Is natural language really the best general-purpose medium for thought?
            </li>
            <li> 
              <strong>Cognitively-inspired interpretability.</strong>
              How can we repurpose methodologies & frameworks from cognitive science & computational neuroscience to 
              understand the internal workings of modern models?
              Conversely, what can probing them reveal about human intelligence?
            </li>
            <li> 
              <strong>Representational alignment & universality.</strong>
              To what extent do intelligent systems converge on a shared representational space?
              What are the key representational differences between humans and machines, and how can we bridge them?
              How can we design benchmarks and evaluation protocols that enable meaningful human–machine comparisons?
            </li>
          </ul>
          <div class="tag-list" aria-hidden="true">
            <span class="tag">interpretability</span>
            <span class="tag">symbols</span>
            <span class="tag">representational alignment</span>
            <span class="tag">cognitive science</span>
            <span class="tag">multimodal reasoning</span>
            <span class="tag">vision-language models</span>
          </div>
        </section>

        <section class="section-card publications-card" aria-labelledby="publications-heading">
          <h2 id="publications-heading">{{  publications  }}</h2>
          <div class="publications-scroll">
            <ul>
              <li>Satchel Grant, Simon Jerome Han, <strong>Alexa R. Tartaglini</strong>, & Christopher Potts. <a href="https://arxiv.org/abs/2511.04638" target="_blank" rel="noopener noreferrer">Addressing divergent representations from causal interventions on neural networks.</a> <em>Under review</em> (2025)</li>
              <li><strong>Alexa R. Tartaglini</strong>, Satchel Grant, Daniel Wurgaft, Christopher Potts & Judith E. Fan. <a href="https://arxiv.org/abs/2510.21740" target="_blank" rel="noopener noreferrer">Diagnosing Bottlenecks in Data Visualization Understanding by Vision-Language Models.</a> <em>Under review</em> (2025)</li>
              <li>Satchel Grant & <strong>Alexa R. Tartaglini</strong>. <a href="https://openreview.net/forum?id=1aZeCatGfy&referrer=%5Bthe+profile+of+Alexa_R._Tartaglini1%5D%28%2Fprofile%3Fid%3D~Alexa_R._Tartaglini1%29" target="_blank" rel="noopener noreferrer">Control and Predictivity in Neural Interpretability.</a> NeurIPS MechInterp Workshop (2025)</li>
              <li>Michael A. Lepori, <strong>Alexa R. Tartaglini</strong>, Wai Keen Vong, Thomas Serre, Brenden M. Lake & Ellie Pavlick. <a href="https://arxiv.org/abs/2406.15955" target="_blank" rel="noopener noreferrer">Beyond the Doors of Perception: Vision Transformers Represent Relations Between Objects.</a> NeurIPS (2024)</li>
              <li><strong>Alexa R. Tartaglini</strong>, Sheridan Feucht, Michael A. Lepori, Wai Keen Vong, Charles Lovering, Brenden M. Lake & Ellie Pavlick. <a href="https://arxiv.org/abs/2310.09612" target="_blank" rel="noopener noreferrer">Deep Neural Networks Can Learn Generalizable Same-Different Visual Relations.</a> Computational Cognitive Neuroscience Proceedings (2023)</li>
              <li><strong>Alexa R. Tartaglini</strong>, Wai Keen Vong, Brenden M. Lake. <a href="https://collaborate.princeton.edu/en/publications/a-developmentally-inspired-examination-of-shape-versus-texture-bi" target="_blank" rel="noopener noreferrer">A Developmentally-Inspired Examination of Shape versus Texture Bias in Machines.</a> CogSci; <em>oral</em> (2022)</li>
              <li><strong>Alexa R. Tartaglini</strong>, Wai Keen Vong & Brenden M. Lake. <a href="https://escholarship.org/uc/item/6tm8664n" target="_blank" rel="noopener noreferrer">Modeling artificial category learning from pixels: Revisiting Shepard, Hovland, and Jenkins (1961) with deep neural networks.</a> CogSci (2021)</li>
            </ul>
          </div>
        </section>

        <section class="section-card" aria-labelledby="contact-heading">
          <h2 id="contact-heading">::  contact  ::</h2>
          <p>I’m always excited to collaborate or exchange ideas. If you'd like to talk about my work, your work, or anything really, please reach out!</p>
          <div class="contact-grid">
            <div>
              <strong style="color: #000">:: email</strong><br />
              <a href="mailto:alexart@stanford.edu">alexart@stanford.edu</a>
            </div>
            <div>
              <strong>:: location</strong><br />
              Stanford University<br />
              Stanford, CA 94305
            </div>
            <div>
              <strong>:: elsewhere</strong><br />
              Check out my social links above! Most active on Twitter/X. 
            </div>
          </div>
        </section>
      </div>
    </div>
  </main>

  <footer>
    <p>&copy; <span id="year"></span> Alexa Tartaglini.</p>
  </footer>

  <script>
    const year = document.getElementById('year');
    if (year) {
      year.textContent = new Date().getFullYear();
    }
  </script>
  <script src="https://cdn.jsdelivr.net/npm/p5@1.9.3/lib/p5.min.js" defer></script>
  <script src="assets/js/hero-p5.js" defer></script>
  <script src="assets/js/side-animation-p5.js" defer></script>
</body>

<script>
  (function () {
    function px(n) { return `${Math.max(0, Math.round(n))}px`; }

    function syncHeights() {
      const contentCol = document.querySelector('.content-column');
      const bio = document.querySelector('.bio-card');
      const viz = document.querySelector('.animation-card');
      if (!contentCol || !bio || !viz) return;

      // Expect right column order: research, publications, contact
      const cards = contentCol.querySelectorAll('.section-card');
      const research = cards[0];
      const publications = cards[1];
      const contact = cards[2];

      if (research && publications) {
        const rH = research.getBoundingClientRect().height;
        const pH = publications.getBoundingClientRect().height;

        // If you “fuse” borders with -1px margins between cards,
        // compensate so the visual bottom aligns perfectly.
        const fusedSeamComp = -1; // set to 0 if you removed the -1px seam trick
        bio.style.height = px(rH + pH - fusedSeamComp);
      }

      if (contact) {
        const cH = contact.getBoundingClientRect().height;
        viz.style.height = px(cH + 1);
      }
    }

    // Run on load + whenever layout could change
    window.addEventListener('load', syncHeights, { once: true });
    window.addEventListener('resize', syncHeights);
    // In case fonts/images reflow later:
    document.fonts && document.fonts.ready && document.fonts.ready.then(syncHeights);
    // Mutation observer for any async content changes:
    const mo = new MutationObserver(syncHeights);
    mo.observe(document.documentElement, { subtree: true, childList: true, attributes: true });
  })();
</script>

<script>
  (function () {
    const btn = document.querySelector('.animation-controls .scroll-down');
    if (!btn) return;

    btn.addEventListener('click', function () {
      const header = document.querySelector('header');
      const target = document.querySelector('.layout');
      if (!target) return;

      const headerH = header ? header.offsetHeight : 0;
      const seamComp = 1;
      const targetY = target.getBoundingClientRect().top + window.scrollY - headerH + seamComp;

      // --- slower custom smooth scroll ---
      const startY = window.scrollY;
      const distance = targetY - startY;
      const duration = 1000; // milliseconds — increase this for slower scroll (e.g., 1800, 2000)
      const startTime = performance.now();

      function step(currentTime) {
        const elapsed = currentTime - startTime;
        const progress = Math.min(elapsed / duration, 1);
        // ease-in-out cubic function
        const ease = progress < 0.5
          ? 4 * progress * progress * progress
          : 1 - Math.pow(-2 * progress + 2, 3) / 2;
        window.scrollTo(0, startY + distance * ease);
        if (elapsed < duration) requestAnimationFrame(step);
      }

      requestAnimationFrame(step);
    });
  })();
</script>

<<script>
  (function () {
    const isTouch = matchMedia?.('(hover: none)')?.matches || ('ontouchstart' in window);
    if (!isTouch) return;
  
    function initCustomScrollbar(scroller) {
      const track = scroller.querySelector('.custom-scrollbar');
      const thumb = track?.querySelector('.thumb');
      if (!track || !thumb) return;
  
      function update() {
        // Ensure the overlay track exactly matches the visible viewport of the scroller
        const ch = scroller.clientHeight;     // viewport height
        const sh = scroller.scrollHeight;     // total content height
        const st = scroller.scrollTop;        // scroll offset
  
        // Track spans the viewport, not the content
        track.style.height = ch + 'px';
  
        // Hide if no overflow
        if (sh <= ch + 1) {
          track.style.display = 'none';
          return;
        } else {
          track.style.display = 'block';
        }
  
        // Thumb height proportional to visible fraction, with minimum size
        const thumbH = Math.max((ch / sh) * ch, 24);
        const maxTop = ch - thumbH;
        const top = Math.min(maxTop, (st / (sh - ch)) * maxTop);
  
        thumb.style.height = thumbH + 'px';
        thumb.style.transform = `translateY(${top}px)`;
      }
  
      scroller.addEventListener('scroll', update, { passive: true });
      addEventListener('resize', update);
  
      // Track layout/content changes too
      const mo = new MutationObserver(update);
      mo.observe(scroller, { childList: true, subtree: true, characterData: true });
  
      // Initial settle after fonts/images
      requestAnimationFrame(update);
      setTimeout(update, 100);
    }
  
    document.querySelectorAll('.bio-card .bio-scroll, .publications-card .publications-scroll')
      .forEach(initCustomScrollbar);
  })();
  </script>  
  
</html>
