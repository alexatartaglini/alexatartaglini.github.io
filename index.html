<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Alexa Tartaglini | About</title>
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="assets/css/main.css" />
</head>
<body class="about-page">
  <header>
    <nav class="navbar" aria-label="Primary navigation">
      <a class="brand" href="index.html">
        <h1>Alexa Tartaglini</h1>
        <span>Computer Science PhD · Stanford University</span>
      </a>
      <div class="nav-links" role="list">
        <a class="nav-link active" href="index.html">about</a>
        <a class="nav-link" href="cv.html">cv</a>
        <a class="nav-link" href="misc.html">misc</a>
      </div>
      <div class="social-links" aria-label="Social links">
        <a href="#" aria-label="Google Scholar" title="Google Scholar">
          <svg width="22" height="22" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true"><path d="M12 2 1.5 9l2.73 1.82A6 6 0 0 1 12 9a6 6 0 0 1 7.77 1.82L21 9 12 2Zm0 9a4 4 0 1 0 3.21 6.39l-3.3 2.34a1 1 0 0 1-1.14 0L5 16.25V18l7 4 7-4v-1.75l-2.12 1.48A4 4 0 0 0 12 11Z"/></svg>
        </a>
        <a href="#" aria-label="GitHub" title="GitHub">
          <svg width="22" height="22" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true"><path d="M12 2a10 10 0 0 0-3.16 19.49c.5.09.68-.21.68-.47v-1.7c-2.78.61-3.37-1.34-3.37-1.34-.45-1.16-1.1-1.47-1.1-1.47-.9-.62.07-.61.07-.61 1 .07 1.53 1.02 1.53 1.02.9 1.52 2.36 1.08 2.94.82a2.14 2.14 0 0 1 .64-1.35c-2.22-.25-4.56-1.11-4.56-4.93a3.87 3.87 0 0 1 1.03-2.69 3.6 3.6 0 0 1 .1-2.65s.84-.27 2.75 1.02a9.48 9.48 0 0 1 5 0c1.91-1.29 2.75-1.02 2.75-1.02a3.6 3.6 0 0 1 .1 2.65 3.87 3.87 0 0 1 1.03 2.69c0 3.83-2.35 4.68-4.58 4.93a2.39 2.39 0 0 1 .69 1.85v2.75c0 .27.18.57.69.47A10 10 0 0 0 12 2Z"/></svg>
        </a>
        <a href="#" aria-label="Twitter" title="Twitter">
          <svg width="22" height="22" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true"><path d="M21 5.92a5.65 5.65 0 0 1-1.74.5 3.06 3.06 0 0 0 1.33-1.7 6 6 0 0 1-1.9.76A3 3 0 0 0 12 7.54a8.46 8.46 0 0 1-6.28-3.2A3 3 0 0 0 6.9 9.44a3 3 0 0 1-1.36-.38v.04A3 3 0 0 0 8.9 12a3 3 0 0 1-1.35.05 3 3 0 0 0 2.81 2.07A6 6 0 0 1 4 16.93 8.42 8.42 0 0 0 8.29 18c5.38 0 8.32-4.67 8.32-8.72v-.4A5.94 5.94 0 0 0 21 5.92Z"/></svg>
        </a>
      </div>
    </nav>
  </header>

  <main>
    <section class="hero" aria-labelledby="hero-heading">
      <canvas id="network-canvas" role="presentation"></canvas>
      <div class="hero-content">
        <h2 id="hero-heading">Interpreting how machines perceive the world</h2>
        <p>
          I study deep neural network interpretability with a focus on vision. My work draws from cognitive science and
          neuroscience to understand what modern models learn, why they succeed, and how we can align them with human goals.
        </p>
      </div>
      <div class="animation-controls" role="group" aria-label="Animation controls">
        <button type="button" data-control="play" aria-pressed="false">Pause animation</button>
        <button type="button" data-mode="flow" data-active="true">Flow</button>
        <button type="button" data-mode="orbit" data-active="false">Orbit</button>
        <button type="button" data-mode="pulse" data-active="false">Pulse</button>
      </div>
    </section>

    <div class="layout">
      <aside class="bio-card" aria-labelledby="bio-heading">
        <h3 id="bio-heading">bio</h3>
        <img src="assets/images/headshot2.jpg" alt="Alexa Tartaglini" />
        <div class="bio-scroll" tabindex="0">
          <p>
            I’m a first year Computer Science PhD student at Stanford, where I currently think about how machines think. My
            primary research interest is deep neural network interpretability with an emphasis on vision.
          </p>
          <p>
            Prior to Stanford, I completed a double B.A. in mathematics and computer science at NYU’s Courant Institute. I joined
            the Human &amp; Machine Learning Lab in 2019 under the supervision of Brenden Lake and Wai Keen Vong to investigate what
            deep models learn from ImageNet, where they fall short, and how to design <em>species-fair</em> benchmarks.
          </p>
          <p>
            My honors thesis, “Human-Machine Perceptual Divergence: Two Investigations on How Neural Networks See the World,” was
            awarded NYU Minds, Brains, and Machines Initiative’s Robert J. Glushko Prize.
          </p>
          <p>
            I was also a trainee in NYU’s NIH Training Program in Computational Neuroscience, mentored by Wei Ji Ma. That experience
            continues to shape how I think about bridging human and machine perception.
          </p>
          <p>
            Before starting my PhD, I spent 2023–2024 as a Research Scientist at NYU’s Center for Data Science working with Ellie
            Pavlick and Brown University’s Language Understanding and Representation Lab on teaching Vision Transformers abstract
            visual relations and interpreting why they excel.
          </p>
          <p>If you’d like to collaborate or exchange ideas, feel free to reach out!</p>
        </div>
      </aside>

      <section class="section-card section-card--research" aria-labelledby="research-heading">
        <h2 id="research-heading">>>  research directions  <<</h2>
        <p>
          I build computational tools to probe and align large vision, language, and multimodal models. Recent threads include:
        </p>
        <ul>
          <li>Characterizing the internal representations that Vision Transformers form for abstract visual relations.</li>
          <li>Designing benchmarks and evaluation protocols that enable meaningful human–machine comparisons.</li>
          <li>Translating ideas from computational neuroscience into mechanistic interpretability for modern models.</li>
        </ul>
        <div class="tag-list" aria-hidden="true">
          <span class="tag">interpretability</span>
          <span class="tag">vision transformers</span>
          <span class="tag">representational alignment</span>
          <span class="tag">cognitive science</span>
        </div>
      </section>

      <section class="section-card section-card--publications" aria-labelledby="publications-heading">
        <h2 id="publications-heading">\\  selected publications  //</h2>
        <ul>
          <li>
            <strong>Human-Machine Perceptual Divergence:</strong> Two investigations on how neural networks see the world. Honors
            thesis, NYU Minds, Brains, and Machines Initiative Robert J. Glushko Prize, 2023.
          </li>
          <li>
            <strong>Teaching Vision Transformers Abstract Relations:</strong> Ongoing work with Ellie Pavlick and collaborators on
            grounding relational reasoning in large-scale vision models (in progress).
          </li>
          <li>
            Additional manuscripts and talks coming soon — reach out if you’d like an early copy or to chat.
          </li>
        </ul>
      </section>

      <section class="sidebar-card" aria-labelledby="sidebar-animation-heading">
        <h3 id="sidebar-animation-heading">signal sketchpad</h3>
        <canvas id="sidebar-animation" role="presentation"></canvas>
        <p>
          A playful rendering of drifting signals, inspired by the waveforms I analyze when tracing how models represent vision.
        </p>
      </section>

      <section class="section-card section-card--contact" aria-labelledby="contact-heading">
        <h2 id="contact-heading">::  contact  ::</h2>
        <p>I’m always excited to discuss new ideas, collaborations, or speaking opportunities.</p>
        <div class="contact-grid">
          <div>
            <strong>Email</strong><br />
            <a href="mailto:hello@alexatartaglini.com">hello@alexatartaglini.com</a>
          </div>
          <div>
            <strong>Office</strong><br />
            Gates Computer Science Building<br />
            Stanford University
          </div>
          <div>
            <strong>Elsewhere</strong><br />
            Connect via the social links in the header or drop a note on Twitter.
          </div>
        </div>
      </section>
    </div>

  </main>

  <footer>
    <p>&copy; <span id="year"></span> Alexa Tartaglini. Designed for accessibility and responsive layouts.</p>
  </footer>

  <script>
    const year = document.getElementById('year');
    if (year) {
      year.textContent = new Date().getFullYear();
    }
  </script>
  <script src="assets/js/animation.js" defer></script>
  <script src="assets/js/sidebar-animation.js" defer></script>
</body>
</html>
